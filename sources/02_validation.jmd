---
title: Validation for classifiers
layout: presentation
permalink: validation
---

# Validation for classifiers

## Understanding model fitness

---

# Class agenda

## What we will do

- Use a Naive Bayesian Classifier to create a confusion table
- Measure validation measures on the confusion table
- Discuss the suitability of the model

--

## Why we will do it

- Validation is *fundamental*
- Errors in models can be acceptable
- The same approach works for more complex models

---

# Setting up the environment

We will not need a lot more than for the previous module:

```julia
using DataFrames, DataFramesMeta
import CSV
import Cairo, Fontconfig
using Gadfly
```

To simplify our work, we will add the `StatsBase` package, which will make the
code nicer to write:

```julia
using Statistics
using Distributions
```

---

# Loading the data

We will get the `penguins` data from the previous module -- as a reminder, we
can load them using *pipes*:

```julia; results="hidden"
penguins = 
    joinpath("data", "penguins.csv") |>
    CSV.File |>
    DataFrame |>
    dropmissing
```

Note that we add `dropmissing` (about 10 records) to avoid having to deal with
the issue of `Missing` data (for now).

---

class: split-50

# Naive Bayesian What?

.column[
- A classifier using **distribution** of features values
- Assumes i.i.d. features ("naive")
- Returns the probability of a class given the features ("Bayesian") 
]

--

.column[
- NBC works with a very small data volume
- NBC is *fast* (lookup the PDF for a known distribution)
- NBC is surprisingly effective!
]

---

# Naive Bayes Classifier

For each class $C_k$, we want to calculate $p(C_k | \mathbf{v})$ (where
$\mathbf{v}$ is a vector of features).

Because there are several features and we assume that they are independant,
we can write


$$
p(C_k|\mathbf{v}) \propto p(C_k)\times \prod_i p(v_i | C_k)
$$

This *is* Bayes' rule, with $\propto$ replacing $=$ as we do not divide by $p(\textbf{v})$ which is constant across classes

We finally get the class for an observation as $\text{argmax}\left(p(C_k)\times
\prod_i p(v_i | C_k)\right)$

---

# Getting the distributions for every class

We will build a model to predict if a penguin is a Chinstrap or not. We do
have three classes, but we will simplify this (after the prediction!) as
"Chinstrap" *v.* "$\not$ Chinstrap".

---

class: split-50

# Transforming the data

The data are not expressed in the same unit - we will apply a simple $z$-score
transformation.


.column[
```julia
μ = vec(mean(features, dims=2))
```
]

.column[
```julia
σ = vec(std(features, dims=2))
```
]

--

We can now work on the version of the data where every features as mean 0 and
unit standard deviation:

```julia
nf = (features .- μ)./σ
```

---

class: split-30

# But how does k-NN *works*?

.column[
- Get measurements for an object with **unknwon membership**
- Find out which $k$ known instances have the **closest features**
- Take a **majority consensus** of the class of the neighbors
]

--

.column[
If we have measured the following penguin:

```julia; results="hidden"
pingoo = [12.4, 46.7, 215.3, 4842.0]
```

what is its species, knowing all the data we already have?

This will require a **data transformation** to express the measurements (in
biological units) in the unitless **features space**:

```julia; results="hidden"
nd = (pingoo .- μ)./σ
```

$$
v_\text{pingoo} = [`j round(nd[1]; digits=2)`, `j round(nd[2]; digits=2)`, `j round(nd[3]; digits=2)`, `j round(nd[4]; digits=2)`]^T
$$

]

---

class: split-50

# Measuring the distances

.column[
We can very easily use the Euclidean distance:

```julia; results="hidden"
distances = vec(sqrt.(sum((nf .- nd).^2.0; dims=1)))
```

Let's also plot it to look at the distribution:

```julia
plot(
    y = sort(distances),
    Geom.line,
    Guide.xlabel("Rank of neighbor"),
    Guide.ylabel("Distance")
) |> PNG("figures/knndist.png", dpi=600)
```

Note that $k$-NN does not require to set a *distance* cutoff (so we don't care
too much about the distance distribution)!
]

.column[
![](figures/knndist.png)
]

---

# Getting the class membership of neighbors

We can use `sortperm` to return a *sorted ordering* of the distance vector, and
then use `findall` to get the position of the distances that are the $k$
smallest:

```julia
k = 5
neighbors = findall(sortperm(distances) .<= k)
neighbors'
```

Because we know where the **labels** are stored (`penguins.species`), we can get
the pool of possible species for our object:

```julia
penguins.species[neighbors]
```

---

# Assigning our penguin to a class

Voting is, at this point, as simple as counting the number of times any species
was recommended:

```julia
votes = countmap(penguins.species[neighbors])
```

We can use some basic `sort`ing of the votes to get the most likely species for
the sample:

```julia
first(sort(collect(votes), by = (x) -> x.second, rev=true)).first
```

---

# The "landscape" of k-NN predictions

We will assume that we know of *two* values, and ignore two others:


```julia
ftval = LinRange(-3, 3, 90)
ftcomb = vec(collect(Base.product(ftval, ftval)))
decisions = []
for (f1, f2) in ftcomb
    tv = [f1, f2, 0.0, 0.0]
    distances = vec(sqrt.(sum((nf .- tv).^2.0; dims=1)))
    neighbors = findall(sortperm(distances) .<= 5)
    votes = countmap(penguins.species[neighbors])
    decision = first(sort(collect(votes), by = (x) -> x.second, rev=true)).first
    push!(decisions, decision)
end
```

---

class: split-50

# Visualizing the predictions (k=5)

.column[
```julia
f1 = [first(c) for c in ftcomb]
f2 = [last(c) for c in ftcomb]
plot(
    x = f1, y = f2,
    color=decisions,
    Geom.rectbin,
    Guide.xlabel("Culmen depth (relative)"),
    Guide.ylabel("Culmen length (relative)"),
    Coord.cartesian(
        xmin=-3, xmax=3, ymin=-3, ymax=3, fixed=true
    )
) |> PNG("figures/knnsim.png", dpi=600) 
```

]

.column[
![](figures/knnsim.png)
]

---

# Intermezzo: turning k-NN into a function

```julia; results="hidden"
function knn(v::Vector{TF}, features::Matrix{TF}, labels::Vector{TL}; k::Integer=5) where {TF <: Number, TL}
    @assert length(v) == size(features, 1)
    @assert length(labels) == size(features, 2)
    @assert 1 <= k <= length(labels)

    Δ = vec(sqrt.(sum((v .- features).^2.0; dims=1)))

    neighbors = findall(sortperm(Δ) .<= k)
    votes = countmap(labels[neighbors])
    decision = first(sort(collect(votes), by = (x) -> x.second, rev=true)).first

    return decision
end
```

```julia; results="hidden"
labels = vec(String.(penguins.species))
features = nf
```

---

# Cross validation

We want to **evaluate** the model on data it **has not seen before**. We call
this **cross-validation**.

--

**Holdout**: the dataset is split in two (training and testing), and we measure
the performance by applying to the model on the testing set, but only informing
it of the training set.

--

**K-fold**: we divide the dataset in $K$ samples, train it on
$K-1$, and evaluate on the remaining one.

--

**Leave-One-Out**: we apply K-fold validation, where $K = n-1$, so that *every
single object* in the dataset is evaluated as a testing set.

---

# Measuring accuracy

One important decision to make when evaluating a model is to decide *which
function is used to measure its performance*.

We will see a lot more when working on binary classifiers.

For the moment, let's have a look at the accurracy function: the proportion of
correct guesses.

--

```julia; results="hidden"
function accuracy(x::Vector{T}, y::Vector{T}) where {T}
    @assert length(x) == length(y)
    return sum(x .== y)/length(x)
end
```

---

# Leave-One-Out cross validation

```julia
guesses = similar(labels)

function loocv!(guesses, features, labels; k=3)
    for i in 1:size(features, 2)
        tf = features[:, setdiff(1:end, i)]
        tl = labels[setdiff(1:end, i)]
        guesses[i] = knn(vec(features[:,i]), tf, tl; k=k)
    end
    return accuracy(guesses, labels)
end

function loocv(features, labels; k=3)
    guesses = similar(labels)
    return loocv!(guesses, features, labels; k=k)
end

loocv!(guesses, features, labels)
```

---

class: split-50

# Can we find the "best" k?

.column[
```julia
K = collect(1:20)

acc = [
    loocv!(
        guesses, features, labels; k=k
    ) for k in K
]

plot(
    x = K, y = acc,
    Geom.point,
    Geom.line,
    Guide.xlabel("Number of neighbors"),
    Guide.ylabel("Accuracy"),
) |> PNG("figures/knnloo.png", dpi=600) 
```

]

.column[
![](figures/knnloo.png)
]
